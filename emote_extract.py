"""
This file contains code to extract all the emotes from the output csv file of the roberta classifier (output_toxicity.csv), and calculate 
details such as the number of times it was seen as toxic and non-toxic. In addition, a toxicity ratio is computed for each emote which defines how toxic an emote is.
The final results are written to a new csv file called Emote_analysis.csv
"""

import pickle
import numpy as np
import pandas as pd


#Function to get global and channel emotes and write them to csv files
def compute_and_write_emotestocsv():
    # Get list of all global emotes
    global_emotes_df = emotes_df[["GLOBAL_TWITCH", "GLOBAL_FFZ", "GLOBAL_7TV"]]
    global_emotes_df = pd.merge(global_emotes_df, bttv_emotes_df["GLOBAL_BTTV"], left_index=True, right_index=True)
    global_emotes_df.fillna("", inplace = True)
    
    #Get list of all channel emotes
    channel_emotes_df = emotes_df.loc[:, ~emotes_df.columns.isin(["TEXT", "GLOBAL_TWITCH", "GLOBAL_FFZ", "GLOBAL_7TV"])]
    channel_bttv_emotes_df = bttv_emotes_df.loc[:, ~bttv_emotes_df.columns.isin(["GLOBAL_BTTV"])]
    channel_ffz_emotes_df = ffz_emotes_df

    channel_total_emotes_df = pd.merge(channel_emotes_df, channel_bttv_emotes_df, on = None, how = "outer")
    channel_total_emotes_df = pd.merge(channel_total_emotes_df, channel_ffz_emotes_df, on = None, how = "outer")
    channel_total_emotes_df.fillna("", inplace = True)

    #Write all global emotes (with extensions) and channel emotes (with extensions) to csv files
    global_emotes_df.to_csv("global_emotes.csv", index = False)
    channel_total_emotes_df.to_csv("channel_emotes.csv", index = False)
    

#Function that reads global emote and channel emote csv files and returns them
def read_emotes_from_csv():
    global_emotes_df = pd.read_csv("global_emotes.csv")

    #Get list of all global emotes (including extensions like BTTV)
    global_emotes1 = [x for x in emotes_df[["GLOBAL_TWITCH", "GLOBAL_FFZ", "GLOBAL_7TV"]].values.flatten() if x != '']
    global_emotes2 = [x for x in bttv_emotes_df["GLOBAL_BTTV"].values.flatten() if x != '']
    global_emotes_list = global_emotes1 + global_emotes2

    #Get dataframe for channel emotes
    channel_emotes_df = pd.read_csv("channel_emotes.csv")

    #Renaming columns that start with numbers to avoid potential conflict with pandas 
    channel_emotes_df.columns = ['Col_' + str(col) if col[0].isdigit() else col for col in channel_emotes_df.columns]
    channel_emotes_df.fillna("", inplace = True)
    channel_emotes_df = channel_emotes_df.reset_index(drop = True)
    
    return [global_emotes_list, channel_emotes_df]


# Function that returns whether the word is a global emote, channel emote or not an emote
def wordIsChannelOrGlobalEmote(word, channel_emotes_df, global_emotes_list): 
    column_with_word = []

    channel = "HasanAbi" #only considering HasanAbi channel for ease of time

    #for channel in channel_emotes_df.columns:
    if (channel_emotes_df[channel] == word).any() and word != "":
        column_with_word.append(channel)

    if word in global_emotes_list:
        return "global" #return that its global
    elif len(column_with_word) > 0:
        return column_with_word[0].removeprefix("Col_") #return channel name 
    else:
        return "No" #not an emote
    
    
#Load emotes from pickle files into pandas dataframes
#emotes_df has the global twitch, global ffz, global 7tv, and then the base emotes for all streamer channels
with open('Data/emote_dict', 'rb') as f:
    emotes_df = pickle.load(f) #255 rows x 2383 columns
    emotes_df.replace(['NaN', 'nan'], np.nan, inplace = True) 
    emotes_df.fillna("", inplace = True)


#bttv_emotes has global bttv emotes in one column and then bttv emotes from streamers in other columns
with open('Data/bttv_dict', 'rb') as f:
    bttv_emotes_df = pickle.load(f) #495 rows x 2023 columns
    bttv_emotes_df.replace(['NaN', 'nan'], np.nan, inplace = True)
    bttv_emotes_df.fillna("", inplace = True)

#ffz_emotes has ffz emotes from streamers
with open('Data/ffz_dict', 'rb') as f:
    ffz_emotes_df = pickle.load(f).T #76 rows x 321 columns
    ffz_emotes_df.replace(['NaN', 'nan'], np.nan, inplace = True)
    ffz_emotes_df.fillna("", inplace = True)

# print(emotes_df)
# print(bttv_emotes_df)
# print(ffz_emotes_df)


#Only need to compute_and_writetocsv() once to write all the emotes to the csv files
#compute_and_write_emotestocsv()

global_emotes_list, channel_emotes_df = read_emotes_from_csv()

#Read toxicity csv file output generated by robertaclassifier.py
#only need comment and toxic column
toxicity_df = pd.read_csv("output_toxicity.csv", usecols = ["comment", "toxic"])
toxicity_df = toxicity_df.dropna() #remove rows with null values


#This will contain the emote as a key and then the values will be the # of times emote was toxic, number of times not toxic and then whether it is global or channel emote
emote_toxicity_dict = {}

counter = 0
#Go through each row in dataframe
for index, row in toxicity_df.iterrows():    
    wordsList = row["comment"].split(" ") #Get list of words from each comment

    for word in wordsList: #go through each word in comment
        wordIsEmote = wordIsChannelOrGlobalEmote(word, channel_emotes_df, global_emotes_list) 

        if wordIsEmote == "No":
            continue #not an emote so ignore this word

        elif wordIsEmote == "global": #global emote
            if word in emote_toxicity_dict: #if this emote was already added
                if row["toxic"] == "no": #not toxic emote
                    emote_toxicity_dict[word][1] += 1 #increment number of times not toxic
                else: #toxic emote
                    emote_toxicity_dict[word][0] += 1 #increment number of times it was toxic

            else: #if this emote was not in toxic dictionary before
                if row["toxic"] == "no": #not toxic emote
                    emote_toxicity_dict[word] = [0,1, True, False]
                else: #toxic emote
                    emote_toxicity_dict[word] = [1,0,True, False]

        else: #channel emote
            if word in emote_toxicity_dict: #if this emote was already added
                if row["toxic"] == "no": #not toxic emote
                    emote_toxicity_dict[word][1] += 1 #increment number of times not toxic
                else: #toxic emote
                    emote_toxicity_dict[word][0] += 1 #increment number of times it was toxic

            else: #if this emote was not in toxic dictionary before
                if row["toxic"] == "no": #not toxic emote
                    emote_toxicity_dict[word] = [0,1, False, wordIsEmote]
                else: #toxic emote
                    emote_toxicity_dict[word] = [1,0,False, wordIsEmote]
    counter += 1

    #status update every 1000 rows
    if counter % 1000 == 0:
        print(str(counter) + " rows have been processed")       



# Convert dictionary to dataframe and write results to final csv file
df = pd.DataFrame.from_dict(emote_toxicity_dict, orient='index', columns = ['Number of times emote was toxic', 'Number of times emote was NOT toxic', "Global emote", "Channel emote"])
df = df.rename_axis('Emote').reset_index()

print(df.head())

#df["Number of times emote was used"] = df["Number of times emote was NOT toxic"] + df["Number of times emote was toxic"]
df["Toxicity Ratio"] = df["Number of times emote was toxic"] / (df["Number of times emote was NOT toxic"] + df["Number of times emote was toxic"]) #last column to provide us with toxicity ratio

df.to_csv("Emote_analysis.csv")
